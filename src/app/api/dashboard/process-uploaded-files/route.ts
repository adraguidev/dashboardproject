import { NextRequest, NextResponse } from 'next/server'
import { S3Client, GetObjectCommand } from '@aws-sdk/client-s3'
import { neon } from '@neondatabase/serverless'
import { Readable, Writable } from 'stream'
import { pipeline } from 'stream/promises'
import csvParser from 'csv-parser'
import { Workbook } from 'exceljs'
import * as path from 'path'

// Configuraci√≥n de Cloudflare R2
const r2Client = new S3Client({
  region: 'auto',
  endpoint: process.env.CLOUDFLARE_R2_ENDPOINT!,
  credentials: {
    accessKeyId: process.env.CLOUDFLARE_R2_ACCESS_KEY_ID!,
    secretAccessKey: process.env.CLOUDFLARE_R2_SECRET_ACCESS_KEY!,
  },
})

const BUCKET_NAME = process.env.CLOUDFLARE_R2_BUCKET_NAME!

// Esquema can√≥nico para asegurar que las tablas siempre tengan las columnas correctas.
const canonicalSchema = {
  table_ccm: [
    "textbox4", "dependencia", "anio", "mes", "numerotramite", "ultimaetapa",
    "fechaexpendiente", "fechaetapaaprobacionmasivafin", "fechapre", "operadorpre",
    "estadopre", "estadotramite", "archivo_origen", "operador", "fecha_asignacion",
    "modalidad", "regimen", "meta_antigua", "meta_nueva", "equipo"
  ],
  table_prr: [
    "textbox4", "dependencia", "anio", "mes", "numerotramite", "ultimaetapa",
    "fechaexpendiente", "fechaetapaaprobacionmasivafin", "fechapre", "operadorpre",
    "estadopre", "estadotramite", "archivo_origen", "operador", "fecha_asignacion",
    "modalidad", "regimen", "meta_antigua", "meta_nueva", "equipo"
  ]
};

const dateColumns = [
  "fechaexpendiente",
  "fechaetapaaprobacionmasivafin", 
  "fechapre",
  "fecha_asignacion"
]

export async function POST(request: NextRequest) {
  console.log('üîÑ Iniciando procesamiento de archivos desde R2...');
  
  try {
    // Verificar variables de entorno
    if (!process.env.DATABASE_DIRECT_URL) {
      throw new Error('Variable DATABASE_DIRECT_URL no configurada');
    }

    const body = await request.json();
    const { files } = body;

    if (!files || !Array.isArray(files) || files.length === 0) {
      return NextResponse.json(
        { error: 'Debes proporcionar informaci√≥n de los archivos a procesar.' },
        { status: 400 }
      );
    }

    // Iniciar procesamiento en background (NO ESPERAR)
    processFilesFromR2(files).catch(error => {
      console.error('‚ùå Error en procesamiento desde R2:', error);
    });

    console.log('‚úÖ Procesamiento iniciado desde R2. Respondiendo inmediatamente.');

    // Responder inmediatamente
    return NextResponse.json({
      success: true,
      message: 'Procesamiento de archivos iniciado desde R2.',
      files: files.map(f => ({ fileName: f.fileName, table: f.table })),
      status: 'processing',
      estimatedTime: '3-8 minutos para completarse',
      note: 'Los datos aparecer√°n en el dashboard autom√°ticamente cuando est√© listo.'
    }, { status: 202 }); // 202 Accepted

  } catch (error) {
    console.error('‚ùå Error iniciando procesamiento desde R2:', error);
    
    return NextResponse.json(
      { 
        error: 'Error al procesar archivos desde R2',
        details: error instanceof Error ? error.message : 'Error desconocido'
      },
      { status: 500 }
    );
  }
}

// L√≥gica principal de procesamiento en background
async function processFilesFromR2(files: Array<{fileName: string, key: string, table: string}>) {
  console.log('[Stream] üîÑ Iniciando procesamiento en background...');
  // Nota: La conexi√≥n a la BD se pasa a la funci√≥n que procesa cada archivo
  // para asegurar que las conexiones se manejan de forma aislada.
  const sql = neon(process.env.DATABASE_DIRECT_URL!);

  for (const fileInfo of files) {
    try {
      // Se pasa la conexi√≥n `sql` a la funci√≥n que procesa cada archivo
      await processSingleFileStream(fileInfo, sql);
    } catch (error) {
      console.error(`[Stream] ‚ùå Error fatal procesando ${fileInfo.fileName}:`, error);
      // Aqu√≠ se podr√≠a a√±adir l√≥gica para reintentos o para notificar el fallo
    }
  }

  // Conversi√≥n de fechas post-procesamiento para todas las tablas
  console.log('[Stream] üóìÔ∏è  Iniciando conversi√≥n de columnas de fecha a tipo DATE...');
  await convertAllDateColumns(sql);
  console.log('[Stream] ‚úÖ Conversi√≥n de fechas completada.');
}

// Procesa un √∫nico archivo usando streams, de forma m√°s robusta
async function processSingleFileStream(fileInfo: {fileName: string, key: string, table: string}, sql: any) {
    const { fileName, key, table } = fileInfo;
    console.log(`[Stream] üöÄ Comenzando a procesar: ${fileName} para la tabla ${table}`);

    const r2Stream = await getR2FileStream(key);
    const canonicalColumns = canonicalSchema[table as keyof typeof canonicalSchema];
    
    // Preparar la tabla: crearla si no existe con el esquema can√≥nico y truncarla
    const colDefs = canonicalColumns.map(col => `"${col}" TEXT`).join(', ');
    await sql.query(`CREATE TABLE IF NOT EXISTS ${table} (${colDefs});`);
    await sql.query(`TRUNCATE TABLE ${table};`);
    console.log(`[Stream] ‚úÖ Tabla ${table} preparada y limpia.`);
    
    let fileHeaders: string[] = [];
    const headerIndexMap: { [key: string]: number } = {}; // Usamos const porque el objeto no se reasigna
    let columnsToInsert: string[] = [];
    let isFirstRow = true;
    let rowCount = 0;
    let processedRowCount = 0;
    const batchSize = 250; // Reducido para dynos con menos memoria, asegura un flujo m√°s constante.
    let batch: any[][] = [];

    const dataStream = createParserStream(fileName, r2Stream);

    console.log(`[Stream] üß† Creado parser para ${fileName}, iniciando iteraci√≥n...`);

    for await (const row of dataStream) {
        rowCount++;
        if (isFirstRow) {
            fileHeaders = row.map((h: any) => String(h || '').trim().replace(/\s+/g, '_').replace(/-/g, '_').toLowerCase());
            fileHeaders.forEach((col, index) => { if(col) headerIndexMap[col] = index; });
            columnsToInsert = canonicalColumns.filter(col => headerIndexMap.hasOwnProperty(col));
            isFirstRow = false;

            if (columnsToInsert.length === 0) {
                throw new Error(`No se encontraron columnas compatibles en el archivo ${fileName} para el esquema de la tabla ${table}.`);
            }
            console.log(`[Stream] üó∫Ô∏è  Mapeadas ${columnsToInsert.length} columnas desde ${fileName}.`);
            continue; // Saltar la fila de cabecera
        }

        const processedRow = processRowData(row, fileHeaders);
        const dbRow = columnsToInsert.map(colName => processedRow[headerIndexMap[colName]]);
        batch.push(dbRow);

        if (batch.length >= batchSize) {
            await insertBatch(sql, table, columnsToInsert, batch);
            processedRowCount += batch.length;
            console.log(`[Stream] üì¶ Lote de ${batch.length} insertado. Total: ${processedRowCount}`);
            batch = [];
        }
    }

    if (batch.length > 0) {
        await insertBatch(sql, table, columnsToInsert, batch);
        processedRowCount += batch.length;
    }

    console.log(`[Stream] ‚úÖ Finalizado ${fileName}. Total de filas le√≠das: ${rowCount - 1}, filas procesadas: ${processedRowCount}`);
}

// Funciones de ayuda
async function getR2FileStream(key: string): Promise<Readable> {
  const command = new GetObjectCommand({ Bucket: BUCKET_NAME, Key: key });
  const response = await r2Client.send(command);
  if (!response.Body) throw new Error('No se pudo descargar el archivo de R2');
  return response.Body as Readable;
}

function createParserStream(fileName: string, stream: Readable): Readable {
  const fileExtension = path.extname(fileName).toLowerCase();
  if (fileExtension === '.csv') {
    return stream.pipe(csvParser({ headers: false, separator: ';' }));
  } else if (fileExtension === '.xlsx') {
    const readable = new Readable({ objectMode: true });
    readable._read = () => {}; // No-op, ya que empujaremos datos manualmente

    const workbook = new Workbook();
    workbook.xlsx.read(stream).then(() => {
      const worksheet = workbook.worksheets[0];
      if (worksheet) {
        worksheet.eachRow((row, rowNumber) => {
          const values = row.values as any[];
          // exceljs usa un array 1-based, lo convertimos a 0-based
          readable.push(values.slice(1));
        });
      }
      readable.push(null); // Fin del stream
    }).catch(err => readable.emit('error', err));
    
    return readable;
  } else {
    throw new Error(`Formato de archivo no soportado: ${fileName}`);
  }
}

function processRowData(row: any[], headers: string[]): any[] {
  return row.map((value, index) => {
    const columnName = headers[index];
    if (dateColumns.includes(columnName)) {
      return convertExcelDate(value);
    }
    return value != null ? String(value) : null;
  });
}

function convertExcelDate(value: any): string | null {
  if (value === null || typeof value === 'undefined') return null;
  if (typeof value === 'object' && value instanceof Date) {
    return value.toISOString().split('T')[0];
  }
  if (typeof value === 'number' && value > 0 && value < 2958466) { // Rango de fechas de Excel
    const jsDate = new Date(Date.UTC(1899, 11, 30, 0, 0, 0, 0) + value * 86400000);
    return jsDate.toISOString().split('T')[0];
  }
  if (typeof value === 'string') {
    try {
      return new Date(value).toISOString().split('T')[0];
    } catch {
      return null;
    }
  }
  return null;
}

async function insertBatch(sql: any, table: string, columns: string[], batch: any[][]) {
  const valueGroups = [];
  const allValues = [];
  let placeholderIndex = 1;

  for (const row of batch) {
    const placeholders = [];
    for (const value of row) {
      placeholders.push(`$${placeholderIndex++}`);
      allValues.push(value);
    }
    valueGroups.push(`(${placeholders.join(', ')})`);
  }

  const columnNames = columns.map(col => `"${col}"`).join(', ');
  const query = `INSERT INTO ${table} (${columnNames}) VALUES ${valueGroups.join(', ')}`;
  
  await sql.query(query, allValues);
}

async function convertAllDateColumns(sql: any) {
  for (const table in canonicalSchema) {
    for (const col of dateColumns) {
      try {
        const alterQuery = `
          ALTER TABLE ${table}
          ALTER COLUMN "${col}" TYPE DATE
          USING CASE 
            WHEN "${col}" IS NULL OR "${col}" = '' THEN NULL
            ELSE "${col}"::DATE
          END;
        `;
        await sql.query(alterQuery);
      } catch (error) {
        // Ignorar error si la columna no existe en esa tabla particular
        if (!(error instanceof Error && error.message.includes('column "') && error.message.includes('" of relation "') && error.message.includes('" does not exist'))) {
          console.error(`[Stream] ‚ùå Error convirtiendo ${col} en ${table}:`, error);
        }
      }
    }
  }
} 